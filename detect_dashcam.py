import cv2
import time
import torch, torchvision
from ultralytics import YOLO
import numpy as np
import argparse
from pathlib import Path
import platform
import os

def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(
        description='D√©tection en temps r√©el avec YOLOv8 - Support fichier et cam√©ra',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:

MODE FICHIER VID√âO:
  python detect_dashcam.py --video video.mp4

MODE TEMPS R√âEL (WEBCAM):
  python detect_dashcam.py --camera 0  # Webcam par d√©faut
  python detect_dashcam.py --camera 1  # Webcam externe
        """
    )
    
    # Source input
    source_group = parser.add_mutually_exclusive_group(required=True)
    source_group.add_argument('--video', '-v', help='Chemin vers le fichier vid√©o')
    source_group.add_argument('--camera', '-c', help='ID de la cam√©ra (0, 1, etc.)')
    
    # Options additionnelles
    parser.add_argument('--output', '-o', default=None, help='Sauvegarder la vid√©o annot√©e')
    parser.add_argument('--conf', default=0.25, type=float, help='Seuil de confiance (d√©faut: 0.25)')
    parser.add_argument('--iou', default=0.55, type=float, help='Seuil IoU pour NMS (d√©faut: 0.55)')
    parser.add_argument('--scale', default=0.75, type=float, help='√âchelle de redimensionnement (d√©faut: 0.75)')
    parser.add_argument('--skip', default=2, type=int, help='Nombre de frames √† ignorer (d√©faut: 2)')
    parser.add_argument('--list-cameras', action='store_true', help='Lister les cam√©ras disponibles')
    
    args = parser.parse_args()
    
    # Lister les cam√©ras disponibles si demand√©
    if args.list_cameras:
        list_available_cameras()
        return
    
    # ‚îÄ‚îÄ‚îÄ 1. Chargement des mod√®les ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("üîÑ Chargement des mod√®les YOLOv8...")
    model_coco  = YOLO('yolov8n.pt')    # 80 classes COCO
    model_signs = YOLO('best.pt')       # mod√®le traffic‚Äësign

    model_coco.to('cpu')
    model_signs.to('cpu')

    SIGN_OFFSET = len(model_coco.names)   # =80
    names = model_coco.names.copy()
    names.update({k + SIGN_OFFSET: v for k, v in model_signs.names.items()})
    print("‚úÖ Mod√®les charg√©s avec succ√®s")

    # ‚îÄ‚îÄ‚îÄ 2. Param√®tres globaux ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    cv2.setNumThreads(6)
    
    # Initialiser la source vid√©o
    is_video_file = False
    total_frames = 0
    
    if args.video:
        print(f"üìπ Ouverture du fichier vid√©o: {args.video}")
        cap = cv2.VideoCapture(args.video)
        source_name = Path(args.video).name
        is_video_file = True
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    else:
        try:
            camera_id = int(args.camera)
            print(f"üì∑ Connexion √† la webcam: {camera_id}")
            
            # Configuration sp√©cifique pour macOS
            if platform.system() == 'Darwin':
                print("üçé D√©tection de macOS - Configuration sp√©ciale pour la cam√©ra...")
                cap = configure_mac_camera(camera_id)
            else:
                cap = cv2.VideoCapture(camera_id)
                
            source_name = f"Webcam-{camera_id}"
            
            # V√©rifier si la cam√©ra est ouverte
            if not cap.isOpened():
                print(f"‚ùå Impossible d'ouvrir la cam√©ra {camera_id}")
                print("üí° Essayez avec --list-cameras pour voir les cam√©ras disponibles")
                return
            
            # Tester la lecture d'une frame
            ret, test_frame = cap.read()
            if not ret:
                print(f"‚ùå La cam√©ra {camera_id} est d√©tect√©e mais ne peut pas √™tre lue")
                print("üí° Essayez une autre cam√©ra ou v√©rifiez les permissions")
                return
            
            print("‚úÖ Cam√©ra connect√©e et fonctionnelle")
            
        except ValueError:
            print(f"‚ùå ID de cam√©ra invalide: {args.camera}")
            return
    
    if not cap.isOpened():
        print("‚ùå Erreur √† l'ouverture de la source vid√©o")
        return

    frame_w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps_src  = cap.get(cv2.CAP_PROP_FPS)
    print(f"üìä R√©solution vid√©o : {frame_w}x{frame_h}, FPS source : {fps_src}")
    
    if is_video_file:
        print(f"üìä Nombre total de frames : {total_frames}")

    # Initialiser l'enregistreur vid√©o si demand√©
    video_writer = None
    if args.output:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_path = args.output
        video_writer = cv2.VideoWriter(
            output_path, fourcc, fps_src,
            (frame_w, frame_h)
        )
        print(f"üíæ Enregistrement vid√©o activ√©: {output_path}")

    # Param√®tres de d√©tection
    scale       = args.scale
    res_w, res_h = int(frame_w*scale), int(frame_h*scale)

    conf_thr    = args.conf
    iou_thr     = args.iou
    skip_frames = args.skip
    relevant_coco = [0,1,2,3,5,7,9,11]

    # ‚îÄ‚îÄ‚îÄ 3. Initialisation de l'interface ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    window_name = "D√©tection Dashcam - YOLOv8 Fusion"
    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
    
    # Cr√©er une barre de progression pour la vid√©o (seulement pour les fichiers vid√©o)
    if is_video_file:
        cv2.createTrackbar('Position', window_name, 0, max(1, total_frames-1), lambda x: None)
        
    # Variables de contr√¥le
    paused = False
    slider_was_used = False
    current_pos = 0
    
    # ‚îÄ‚îÄ‚îÄ 4. Boucle principale ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print("\nüöÄ D√©marrage de la d√©tection en temps r√©el...")
    print("üí° Contr√¥les:")
    print("  ‚Ä¢ Q: Quitter")
    print("  ‚Ä¢ ESPACE: Pause/Reprendre")
    print("  ‚Ä¢ S: Screenshot")
    if is_video_file:
        print("  ‚Ä¢ ‚Üê/‚Üí: Reculer/Avancer de 10 secondes")
        print("  ‚Ä¢ Curseur: Navigation dans la vid√©o")
    
    prev_time, fps_hist, frame_count = 0, [], 0
    last_xyxy, last_scores, last_labels = None, None, None
    last_annotated_frame = None
    consecutive_errors = 0
    max_errors = 5

    while True:
        # V√©rifier si la position du curseur a √©t√© modifi√©e (pour les fichiers vid√©o)
        if is_video_file:
            new_pos = cv2.getTrackbarPos('Position', window_name)
            if new_pos != current_pos:
                cap.set(cv2.CAP_PROP_POS_FRAMES, new_pos)
                current_pos = new_pos
                slider_was_used = True
        
        # Si en pause, ne pas lire de nouvelle frame sauf si le curseur a √©t√© utilis√©
        if paused and not slider_was_used:
            # Afficher la derni√®re frame annot√©e avec indication de pause
            if last_annotated_frame is not None:
                pause_frame = last_annotated_frame.copy()
                # Ajouter un indicateur de pause
                cv2.putText(pause_frame, "PAUSE", (frame_w - 120, 40),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
                cv2.imshow(window_name, pause_frame)
            
            # Attendre les commandes clavier
            key = cv2.waitKey(100) & 0xFF
            if key == ord('q'):
                break
            elif key == ord(' '):  # Espace pour reprendre
                paused = False
                print("‚ñ∂Ô∏è Lecture")
            elif key == ord('s'):  # Screenshot
                save_screenshot(last_annotated_frame if last_annotated_frame is not None else frame)
            elif key == 81 and is_video_file:  # Fl√®che gauche (reculer)
                current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
                new_frame = max(0, current_frame - int(fps_src * 10))  # Reculer de 10 secondes
                cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame)
                current_pos = new_frame
                cv2.setTrackbarPos('Position', window_name, current_pos)
                slider_was_used = True
            elif key == 83 and is_video_file:  # Fl√®che droite (avancer)
                current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
                new_frame = min(total_frames - 1, current_frame + int(fps_src * 10))  # Avancer de 10 secondes
                cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame)
                current_pos = new_frame
                cv2.setTrackbarPos('Position', window_name, current_pos)
                slider_was_used = True
                
            continue
        
        # R√©initialiser le flag du curseur
        slider_was_used = False
        
        # Lire une nouvelle frame
        ret, frame = cap.read()
        if not ret:
            consecutive_errors += 1
            print(f"‚ö†Ô∏è Erreur de lecture (tentative {consecutive_errors}/{max_errors})")
            
            if consecutive_errors >= max_errors:
                if is_video_file:  # Si c'est un fichier vid√©o, on peut le red√©marrer
                    print("üîÑ Fin de la vid√©o - Red√©marrage...")
                    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                    current_pos = 0
                    cv2.setTrackbarPos('Position', window_name, 0)
                    consecutive_errors = 0
                    continue
                else:  # Si c'est une webcam, on quitte
                    print("‚ùå Trop d'erreurs de lecture de la cam√©ra")
                    break
            
            # Petite pause avant de r√©essayer
            time.sleep(0.5)
            continue
        
        # Mettre √† jour la position du curseur pour les fichiers vid√©o
        if is_video_file:
            current_pos = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            cv2.setTrackbarPos('Position', window_name, current_pos)
        
        # R√©initialiser le compteur d'erreurs si on a r√©ussi √† lire une frame
        consecutive_errors = 0
        frame_count += 1

        # ‚Äî calcul du FPS liss√©
        now = time.time()
        fps_curr = 1/(now - prev_time) if prev_time else 0
        prev_time = now
        fps_hist.append(fps_curr)
        if len(fps_hist) > 30: fps_hist.pop(0)
        fps_avg = sum(fps_hist) / len(fps_hist)

        if frame_count % skip_frames == 0:
            small = cv2.resize(frame, (res_w, res_h))

            # ‚Üí d√©tection COCO
            r_coco = model_coco.predict(
                small, conf=conf_thr, classes=relevant_coco, verbose=False
            )[0]

            # ‚Üí d√©tection traffic‚Äësign
            r_sign = model_signs.predict(small, conf=conf_thr, verbose=False)[0]
            sign_cls = r_sign.boxes.cls.clone() + SIGN_OFFSET  # clone + offset

            # ‚Üí fusion des bo√Ætes
            xyxy   = torch.cat([r_coco.boxes.xyxy,   r_sign.boxes.xyxy])
            scores = torch.cat([r_coco.boxes.conf,   r_sign.boxes.conf])
            labels = torch.cat([r_coco.boxes.cls,    sign_cls])

            keep = torchvision.ops.nms(xyxy, scores, iou_thr)
            xyxy, scores, labels = xyxy[keep], scores[keep], labels[keep]

            # sauvegarde pour frames ignor√©es
            last_xyxy, last_scores, last_labels = xyxy, scores, labels

            # ‚Üí dessin
            annotated = frame.copy()
            for i in range(len(xyxy)):
                # 1) extraire & convertir
                x1f, y1f, x2f, y2f = xyxy[i].cpu().numpy()
                x1 = int(x1f / scale); y1 = int(y1f / scale)
                x2 = int(x2f / scale); y2 = int(y2f / scale)

                conf = float(scores[i].item())
                cls  = int(labels[i].item())

                # 2) dessiner
                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,255,0), 2)
                txt = f"{names[cls]} {conf:.2f}"
                cv2.putText(annotated, txt, (x1, y1-8),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)

            last_annotated_frame = annotated.copy()

        else:
            # r√©‚Äëaffichage des derni√®res d√©tections
            annotated = frame.copy() if last_annotated_frame is None else last_annotated_frame.copy()
            if last_xyxy is not None:
                for i in range(len(last_xyxy)):
                    x1f, y1f, x2f, y2f = last_xyxy[i].cpu().numpy()
                    x1 = int(x1f / scale); y1 = int(y1f / scale)
                    x2 = int(x2f / scale); y2 = int(y2f / scale)

                    conf = float(last_scores[i].item())
                    cls  = int(last_labels[i].item())

                    cv2.rectangle(annotated, (x1, y1), (x2, y2), (0,255,0), 2)
                    txt = f"{names[cls]} {conf:.2f}"
                    cv2.putText(annotated, txt, (x1, y1-8),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)

        # ‚Äî afficher le FPS et la source
        cv2.putText(annotated, f"FPS: {fps_avg:.1f}", (20,40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
        cv2.putText(annotated, f"Source: {source_name}", (20,80),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
                    
        # Afficher la position actuelle pour les fichiers vid√©o
        if is_video_file:
            current_time = current_pos / fps_src
            total_time = total_frames / fps_src
            time_str = f"{int(current_time//60):02d}:{int(current_time%60):02d}/{int(total_time//60):02d}:{int(total_time%60):02d}"
            cv2.putText(annotated, time_str, (20, 120),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)

        # Enregistrer la vid√©o si demand√©
        if video_writer:
            video_writer.write(annotated)

        cv2.imshow(window_name, annotated)
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord(' '):  # Espace pour pause/reprendre
            paused = not paused
            if paused:
                print("‚è∏Ô∏è Pause")
            else:
                print("‚ñ∂Ô∏è Lecture")
        elif key == ord('s'):  # Screenshot
            save_screenshot(annotated)
        elif key == 81 and is_video_file:  # Fl√®che gauche (reculer)
            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            new_frame = max(0, current_frame - int(fps_src * 10))  # Reculer de 10 secondes
            cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame)
            current_pos = new_frame
            cv2.setTrackbarPos('Position', window_name, current_pos)
        elif key == 83 and is_video_file:  # Fl√®che droite (avancer)
            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            new_frame = min(total_frames - 1, current_frame + int(fps_src * 10))  # Avancer de 10 secondes
            cap.set(cv2.CAP_PROP_POS_FRAMES, new_frame)
            current_pos = new_frame
            cv2.setTrackbarPos('Position', window_name, current_pos)

    # ‚îÄ‚îÄ‚îÄ 5. Lib√©ration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    cap.release()
    if video_writer:
        video_writer.release()
    cv2.destroyAllWindows()
    print("‚úÖ Session termin√©e!")

def save_screenshot(frame):
    """Sauvegarde un screenshot avec horodatage"""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    screenshot_path = f"screenshot_{timestamp}.jpg"
    cv2.imwrite(screenshot_path, frame)
    print(f"üì∏ Screenshot sauvegard√©: {screenshot_path}")

def configure_mac_camera(camera_id):
    """Configuration sp√©ciale pour les cam√©ras sur macOS"""
    cap = cv2.VideoCapture(camera_id)
    
    # R√©glages pour am√©liorer la compatibilit√© avec macOS
    cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
    
    # Essayer diff√©rentes r√©solutions
    resolutions = [(1280, 720), (640, 480), (320, 240)]
    
    for width, height in resolutions:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        
        # Tester si on peut lire une frame
        ret, _ = cap.read()
        if ret:
            print(f"‚úÖ Cam√©ra configur√©e avec succ√®s: {width}x{height}")
            # R√©initialiser la cam√©ra
            cap.release()
            cap = cv2.VideoCapture(camera_id)
            cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            return cap
    
    # Si aucune r√©solution ne fonctionne, essayer sans configuration sp√©ciale
    cap.release()
    return cv2.VideoCapture(camera_id)

def list_available_cameras():
    """Liste les cam√©ras disponibles sur le syst√®me"""
    print("\nüì∑ Recherche des cam√©ras disponibles...")
    
    # Nombre maximum de cam√©ras √† tester
    max_cameras = 10
    available_cameras = []
    
    for i in range(max_cameras):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                available_cameras.append((i, width, height, fps))
            cap.release()
    
    if available_cameras:
        print("‚úÖ Cam√©ras d√©tect√©es:")
        for i, width, height, fps in available_cameras:
            print(f"  ‚Ä¢ Cam√©ra {i}: {width}x{height} @ {fps:.1f} FPS")
        print("\nüí° Utilisez l'option --camera X pour s√©lectionner une cam√©ra")
    else:
        print("‚ùå Aucune cam√©ra n'a √©t√© d√©tect√©e")
        print("üí° V√©rifiez les connexions et les permissions")
    
    if platform.system() == 'Darwin':
        print("\nüçé Note pour macOS:")
        print("  ‚Ä¢ Si vous utilisez une cam√©ra de continuit√© (iPhone/iPad),")
        print("    assurez-vous que l'appareil est d√©verrouill√© et que")
        print("    la fonction est activ√©e dans les R√©glages Syst√®me.")

if __name__ == "__main__":
    main()
